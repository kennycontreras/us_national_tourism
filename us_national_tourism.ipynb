{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# US National Tourism Data Warehouse from Scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project Summary\n",
    "\n",
    "This project was built with the goal of providing wide information for analysis purpose about Immigration data of US. The goal is to create and build a Datawarehouse from scratch with clean and structured data that you can apply machine learning models and BI tools to for example know about what kind of visa every immigrant has, which states or port entries receive more immigrants, average period of stay in the US, visa types, etc. \n",
    "\n",
    "With this information, you can provide an exhaustive analysis about e.g Which state receive more immigrants, which season is the best for travelers based on weather temperature of each state. How many people live in every state or city, airports for each state. You can even apply machine learning models and use this information to promote events or hotel room deals. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Project Life Cycle "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![img](datasets/cycle_1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import psycopg2\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import types as T\n",
    "\n",
    "# Config for postgresql\n",
    "# To execute write statements it's necessary to download Postgres jar and upload into a pyspark jar directory. https://jdbc.postgresql.org/download.html\n",
    "url_db = \"jdbc:postgresql://127.0.0.1:5432/imm_dwh\"\n",
    "properties = {\"user\": \"student\", \"password\": \"student\", \"driver\": \"org.postgresql.Driver\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "The scope of this project is to gather valuable information related to Immigrants and build a structured Datawarehouse that can be helpful to Business Analytics and Machine Learning models. \n",
    "\n",
    "All tables were created with the final to match between each other using the state column. This means that you can select all immigrants for New York State and at the same time know which airports you have available in that state, or know what was the average temperature on a particular day for New York. \n",
    "\n",
    "To build this project we're going to use Spark and Postgres. \n",
    "\n",
    "Spark shine with largest datasets like US National Immigration, that's why we're going to use Spark Dataframes to build all tables. The other reason is that it's really simple to connect with Postgres. \n",
    "Spark provides methods to write directly into Postgres without the necessity to create tables, Spark creates tables by himself. If you want to delete the data before insert in a dimension table, all you have to do is specified \"overwrite\" mode in the write statement, the same for \"append\" mode. \n",
    "\n",
    "Postgres will allow us to create the Datawarehouse as simple as possible and if we want to migrate in the future to Amazon Redshift, it provides good synergy due to Amazon Redshift was build upon Postgres 8.0.2. \n",
    "\n",
    "## Datasets: \n",
    "\n",
    "List of datasets used in this project: \n",
    "\n",
    "- I94 Immigration Data: This data came from the US National Tourism and Trade Office, \n",
    "[this dataset](https://travel.trade.gov/research/reports/i94/historical/2016.html) contains all information about immigrants that travel to the US. In this dataset you will find data like ports of entry, airline, the number of flight, type of visa, date of entry, date until allowed to stay in the US. etc. \n",
    "\n",
    "- Historical Hourly Weather Data: This dataset contains more than 5 years of hourly weather information with various attributes, such as temperature, humidity, air pressure, etc.   [Dataset link](https://www.kaggle.com/selfishgene/historical-hourly-weather-data)\n",
    "\n",
    "- U.S. City Demographic Data: This dataset is from OpenDataSoft, provides all information about the total population for cities and states of the US. You can download the entire dataset here: [link](https://public.opendatasoft.com/explore/dataset/us-cities-demographics/export/)\n",
    "\n",
    "- Airport Code Table: Dataset with all airports for each city and state of the US. Link to download: [here](https://datahub.io/core/airport-codes#data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dimension Tables:\n",
    "\n",
    "    - dim_us_city\n",
    "    - dim_city_temp\n",
    "    - dim_airport\n",
    "    - dim_country\n",
    "    \n",
    "### Fact Table:\n",
    "\n",
    "    - immigration_us\n",
    "    \n",
    "    \n",
    "### Database Model\n",
    "\n",
    "\n",
    "![title](datasets/model.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To execute this project successfully we have two options\n",
    "The first one is to execute cell by cell of this notebook. The second option is to execute a series of scripts created to accomplish the same as this notebook but without all analysis made it here.\n",
    "\n",
    "### Jupyter Notebook option \n",
    "\n",
    "- This is pretty straightforward, we can accomplish this executing cell by cell of this notebook but first, we need to execute a few files to create a database and tables for this project.\n",
    "I recommend executing this project following this notebook because this provides wide information about why we choose some clean methods, how we solve null values, columns, pivot, etc. \n",
    "This will give you more information about how we approached every step of this project.\n",
    "\n",
    "1. Execute `create_tables.py`: This file creates a database called `imm_dwh` and all tables used in this project. \n",
    "2. After that, we can execute all cells of this notebook without a problem.\n",
    "\n",
    "### Python script option\n",
    "\n",
    "- As we said before, we can accomplish the same goal executing a series of python files, the unique difference is that in the script we don't implement analysis methods like print a Dataframe after every clean process. That's the main difference with the Jupyter notebook option.\n",
    "\n",
    "1. Execute `create_tables.py`: This file creates a database called `imm_dwh` and all tables used in this project. \n",
    "2. Execute `etl.py`: This file executes the ETL pipeline to build and write into all tables of the Datawarehouse. \n",
    "\n",
    "### Aditional Information\n",
    "\n",
    "- Data Dictionary: We add a file called `data_dictionary.md` (To be watched on Github without problems) that contains a dictionary an explanation about every column of this Datawarehouse.\n",
    "- SQL Queries: You can find all queries like create tables and select in the file called `sql_queries.py`\n",
    "- Credentials of AWS: Credentials of AWS are already implemented in `etl.py` file, if we want to migrate this project to the cloud. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Dimension Table: `dim_us_city` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a Spark Session, clean and transform the dataset, after that, we can write the dataframe in parquet files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Spark Session \n",
    "spark = SparkSession.builder\\\n",
    "    .appName('national_tourism')\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Median Age</th>\n",
       "      <th>Male Population</th>\n",
       "      <th>Female Population</th>\n",
       "      <th>Total Population</th>\n",
       "      <th>Number of Veterans</th>\n",
       "      <th>Foreign-born</th>\n",
       "      <th>Average Household Size</th>\n",
       "      <th>State Code</th>\n",
       "      <th>Race</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Silver Spring</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>33.8</td>\n",
       "      <td>40601</td>\n",
       "      <td>41862</td>\n",
       "      <td>82463</td>\n",
       "      <td>1562</td>\n",
       "      <td>30908</td>\n",
       "      <td>2.6</td>\n",
       "      <td>MD</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>25924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Quincy</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>41.0</td>\n",
       "      <td>44129</td>\n",
       "      <td>49500</td>\n",
       "      <td>93629</td>\n",
       "      <td>4147</td>\n",
       "      <td>32935</td>\n",
       "      <td>2.39</td>\n",
       "      <td>MA</td>\n",
       "      <td>White</td>\n",
       "      <td>58723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hoover</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>38.5</td>\n",
       "      <td>38040</td>\n",
       "      <td>46799</td>\n",
       "      <td>84839</td>\n",
       "      <td>4819</td>\n",
       "      <td>8229</td>\n",
       "      <td>2.58</td>\n",
       "      <td>AL</td>\n",
       "      <td>Asian</td>\n",
       "      <td>4759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rancho Cucamonga</td>\n",
       "      <td>California</td>\n",
       "      <td>34.5</td>\n",
       "      <td>88127</td>\n",
       "      <td>87105</td>\n",
       "      <td>175232</td>\n",
       "      <td>5821</td>\n",
       "      <td>33878</td>\n",
       "      <td>3.18</td>\n",
       "      <td>CA</td>\n",
       "      <td>Black or African-American</td>\n",
       "      <td>24437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Newark</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>34.6</td>\n",
       "      <td>138040</td>\n",
       "      <td>143873</td>\n",
       "      <td>281913</td>\n",
       "      <td>5829</td>\n",
       "      <td>86253</td>\n",
       "      <td>2.73</td>\n",
       "      <td>NJ</td>\n",
       "      <td>White</td>\n",
       "      <td>76402</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               City          State Median Age Male Population  \\\n",
       "0     Silver Spring       Maryland       33.8           40601   \n",
       "1            Quincy  Massachusetts       41.0           44129   \n",
       "2            Hoover        Alabama       38.5           38040   \n",
       "3  Rancho Cucamonga     California       34.5           88127   \n",
       "4            Newark     New Jersey       34.6          138040   \n",
       "\n",
       "  Female Population Total Population Number of Veterans Foreign-born  \\\n",
       "0             41862            82463               1562        30908   \n",
       "1             49500            93629               4147        32935   \n",
       "2             46799            84839               4819         8229   \n",
       "3             87105           175232               5821        33878   \n",
       "4            143873           281913               5829        86253   \n",
       "\n",
       "  Average Household Size State Code                       Race  Count  \n",
       "0                    2.6         MD         Hispanic or Latino  25924  \n",
       "1                   2.39         MA                      White  58723  \n",
       "2                   2.58         AL                      Asian   4759  \n",
       "3                   3.18         CA  Black or African-American  24437  \n",
       "4                   2.73         NJ                      White  76402  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "us_city_path  = os.getcwd() + '/datasets/us-cities-demographics.csv'\n",
    "df_city = spark.read.format(\"csv\").option(\"header\", \"true\").option(\"delimiter\", \";\").load(us_city_path)\n",
    "df_city.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the purpose of this project, we're going to select just a few columns and transform some others. e.g: We are going to group the data by City. There's no need to sum the population of males and females because the source already did that for us. We can corroborate this by choosing a random city and compare with this link: https://suburbanstats.org/\n",
    "\n",
    "Some columns are going to be discarded like race, n˚ of veterans, avg household size, etc. because don't fit in the purpose of the project.\n",
    "\n",
    "\n",
    "Columns of `dim_us_city`: \n",
    "* __id_city__: Serial, primary key\n",
    "* __city__: Name of the city \n",
    "* __state__: Name of the State of US without abbreviation\n",
    "* __male_population__: Male total population for a city\n",
    "* __female_population__: Female total population for a city\n",
    "* __total_population__: Male + Female population\n",
    "* __state_prefix__: Abbreviation of State name, more information [here](https://en.wikipedia.org/wiki/List_of_U.S._state_abbreviations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>male_population</th>\n",
       "      <th>female_population</th>\n",
       "      <th>total_population</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Saint Cloud</td>\n",
       "      <td>Minnesota</td>\n",
       "      <td>34311</td>\n",
       "      <td>33942</td>\n",
       "      <td>68253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>West Covina</td>\n",
       "      <td>California</td>\n",
       "      <td>51629</td>\n",
       "      <td>56860</td>\n",
       "      <td>108489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Saint Joseph</td>\n",
       "      <td>Missouri</td>\n",
       "      <td>37688</td>\n",
       "      <td>38408</td>\n",
       "      <td>76096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Troy</td>\n",
       "      <td>Michigan</td>\n",
       "      <td>42371</td>\n",
       "      <td>40905</td>\n",
       "      <td>83276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fayetteville</td>\n",
       "      <td>Arkansas</td>\n",
       "      <td>41959</td>\n",
       "      <td>40873</td>\n",
       "      <td>82832</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           city       state male_population female_population total_population\n",
       "0   Saint Cloud   Minnesota           34311             33942            68253\n",
       "1   West Covina  California           51629             56860           108489\n",
       "2  Saint Joseph    Missouri           37688             38408            76096\n",
       "3          Troy    Michigan           42371             40905            83276\n",
       "4  Fayetteville    Arkansas           41959             40873            82832"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns  = ['City', 'State', 'Male Population', 'Female Population', 'Total Population']\n",
    "new_columns = [column.replace(\" \", \"_\").lower() for column in columns]\n",
    "df_city = df_city.select(*columns).dropDuplicates().toDF(*new_columns)\n",
    "df_city.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning for `dim_us_city` table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, it's a good practice to check for null values in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>male_population</th>\n",
       "      <th>female_population</th>\n",
       "      <th>total_population</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Villages</td>\n",
       "      <td>Florida</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>72590</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           city    state male_population female_population total_population\n",
       "0  The Villages  Florida            None              None            72590"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_city.filter((F.col(\"male_population\").isNull() == True) | (F.col(\"female_population\").isNull() == True)).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>male_population</th>\n",
       "      <th>female_population</th>\n",
       "      <th>total_population</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [city, state, male_population, female_population, total_population]\n",
       "Index: []"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_city.filter((F.col(\"city\").isNull() == True) | (F.col(\"state\").isNull() == True) ).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>male_population</th>\n",
       "      <th>female_population</th>\n",
       "      <th>total_population</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [city, state, male_population, female_population, total_population]\n",
       "Index: []"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_city.filter(F.col(\"total_population\").isNull() == True).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have columns `male_population` and `female_population` with null values. \n",
    "\n",
    "Let's change those NaN values using fillna method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>male_population</th>\n",
       "      <th>female_population</th>\n",
       "      <th>total_population</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Villages</td>\n",
       "      <td>Florida</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>72590</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           city    state male_population female_population total_population\n",
       "0  The Villages  Florida               0                 0            72590"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cityFill = df_city.fillna({'male_population': 0, 'female_population': 0})\n",
    "df_cityFill.filter('city = \"The Villages\"').toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we described before, the entire Datawarehouse was created to be joined by State (prefix) column. That's why every table needs to have a `state prefix` column\n",
    "\n",
    "Let's add a state prefix column to this Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>male_population</th>\n",
       "      <th>female_population</th>\n",
       "      <th>total_population</th>\n",
       "      <th>state_prefix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Saint Cloud</td>\n",
       "      <td>Minnesota</td>\n",
       "      <td>34311</td>\n",
       "      <td>33942</td>\n",
       "      <td>68253</td>\n",
       "      <td>MN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>West Covina</td>\n",
       "      <td>California</td>\n",
       "      <td>51629</td>\n",
       "      <td>56860</td>\n",
       "      <td>108489</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Saint Joseph</td>\n",
       "      <td>Missouri</td>\n",
       "      <td>37688</td>\n",
       "      <td>38408</td>\n",
       "      <td>76096</td>\n",
       "      <td>MO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Troy</td>\n",
       "      <td>Michigan</td>\n",
       "      <td>42371</td>\n",
       "      <td>40905</td>\n",
       "      <td>83276</td>\n",
       "      <td>MI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fayetteville</td>\n",
       "      <td>Arkansas</td>\n",
       "      <td>41959</td>\n",
       "      <td>40873</td>\n",
       "      <td>82832</td>\n",
       "      <td>AR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           city       state male_population female_population  \\\n",
       "0   Saint Cloud   Minnesota           34311             33942   \n",
       "1   West Covina  California           51629             56860   \n",
       "2  Saint Joseph    Missouri           37688             38408   \n",
       "3          Troy    Michigan           42371             40905   \n",
       "4  Fayetteville    Arkansas           41959             40873   \n",
       "\n",
       "  total_population state_prefix  \n",
       "0            68253           MN  \n",
       "1           108489           CA  \n",
       "2            76096           MO  \n",
       "3            83276           MI  \n",
       "4            82832           AR  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets.data import Data\n",
    "from pyspark.sql.functions import udf\n",
    "\n",
    "@udf\n",
    "def state_prefix(name):   \n",
    "    prefix = [key for key,value in Data.states.items() if value==name][0]\n",
    "    return prefix\n",
    "   \n",
    "      \n",
    "df_cityState = df_cityFill.withColumn(\"state_prefix\", state_prefix(df_cityFill.state))\n",
    "df_cityState.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Searching for null values in the new column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>male_population</th>\n",
       "      <th>female_population</th>\n",
       "      <th>total_population</th>\n",
       "      <th>state_prefix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [city, state, male_population, female_population, total_population, state_prefix]\n",
       "Index: []"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cityState.filter(F.col(\"state_prefix\").isNull()).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have cleaned and added columns to the Dataframe, we can write the data in a database.\n",
    "\n",
    "Write DataFrame into Postgres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment to execute\n",
    "# df_cityState.write.mode(\"append\").jdbc(url=url_db, table=\"dim_us_city\", properties=properties)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a variable with state and city to add state column in dim_city_temperature (Next dim table to be created)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_city = df_cityState.select(\"state_prefix\", \"city\").dropDuplicates().rdd.map(lambda x: (x[0],x[1])).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Dimension Table: `dim_city_temp` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our main dataset (Immigration) we have only data of United States, that's why we're going to filter or select (due to the original csv is pivot) this dataset by cities only on the US. \n",
    "\n",
    "Columns of `dim_city_temp`: \n",
    "\n",
    "* __id_weather__: Serial, primary key\n",
    "* __datetime__: Date column in format YYYY-MM-DD  \n",
    "* __city__: City of US\n",
    "* __temp__: Average temperature for a City of US. This temperature is grouped by day and city.\n",
    "* __state_prefix__: Abbreviation of State name, more information [here](https://en.wikipedia.org/wiki/List_of_U.S._state_abbreviations)\n",
    "\n",
    "Create a list of cities of US based on the dictionary of our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cities  = pd.read_csv(os.getcwd() + \"/datasets/historical-hourly-weather-data/city_attributes.csv\")\n",
    "us_cities = df_cities[df_cities.Country == \"United States\"]['City'].values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spark Dataframe for dim table, select column based on the US city list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>Portland</th>\n",
       "      <th>San Francisco</th>\n",
       "      <th>Seattle</th>\n",
       "      <th>Los Angeles</th>\n",
       "      <th>San Diego</th>\n",
       "      <th>Las Vegas</th>\n",
       "      <th>Phoenix</th>\n",
       "      <th>Albuquerque</th>\n",
       "      <th>Denver</th>\n",
       "      <th>...</th>\n",
       "      <th>Indianapolis</th>\n",
       "      <th>Atlanta</th>\n",
       "      <th>Detroit</th>\n",
       "      <th>Jacksonville</th>\n",
       "      <th>Charlotte</th>\n",
       "      <th>Miami</th>\n",
       "      <th>Pittsburgh</th>\n",
       "      <th>Philadelphia</th>\n",
       "      <th>New York</th>\n",
       "      <th>Boston</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012-10-01 12:00:00</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-10-01 13:00:00</td>\n",
       "      <td>282.08</td>\n",
       "      <td>289.48</td>\n",
       "      <td>281.8</td>\n",
       "      <td>291.87</td>\n",
       "      <td>291.53</td>\n",
       "      <td>293.41</td>\n",
       "      <td>296.6</td>\n",
       "      <td>285.12</td>\n",
       "      <td>284.61</td>\n",
       "      <td>...</td>\n",
       "      <td>283.85</td>\n",
       "      <td>294.03</td>\n",
       "      <td>284.03</td>\n",
       "      <td>298.17</td>\n",
       "      <td>288.65</td>\n",
       "      <td>299.72</td>\n",
       "      <td>281.0</td>\n",
       "      <td>285.63</td>\n",
       "      <td>288.22</td>\n",
       "      <td>287.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012-10-01 14:00:00</td>\n",
       "      <td>282.083251974</td>\n",
       "      <td>289.474992813</td>\n",
       "      <td>281.797216632</td>\n",
       "      <td>291.868185522</td>\n",
       "      <td>291.533500952</td>\n",
       "      <td>293.403141271</td>\n",
       "      <td>296.608508543</td>\n",
       "      <td>285.154558187</td>\n",
       "      <td>284.607305531</td>\n",
       "      <td>...</td>\n",
       "      <td>283.889393939</td>\n",
       "      <td>294.03534141</td>\n",
       "      <td>284.069789234</td>\n",
       "      <td>298.205229759</td>\n",
       "      <td>288.650172214</td>\n",
       "      <td>299.732517698</td>\n",
       "      <td>281.024767377</td>\n",
       "      <td>285.663207797</td>\n",
       "      <td>288.24767617</td>\n",
       "      <td>287.186092094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012-10-01 15:00:00</td>\n",
       "      <td>282.091866475</td>\n",
       "      <td>289.460618112</td>\n",
       "      <td>281.789832606</td>\n",
       "      <td>291.862844459</td>\n",
       "      <td>291.543355079</td>\n",
       "      <td>293.392177052</td>\n",
       "      <td>296.631487354</td>\n",
       "      <td>285.233951595</td>\n",
       "      <td>284.5999178</td>\n",
       "      <td>...</td>\n",
       "      <td>283.941919192</td>\n",
       "      <td>294.049702185</td>\n",
       "      <td>284.173964682</td>\n",
       "      <td>298.299595186</td>\n",
       "      <td>288.650581705</td>\n",
       "      <td>299.76657946</td>\n",
       "      <td>281.088318736</td>\n",
       "      <td>285.756824139</td>\n",
       "      <td>288.326939663</td>\n",
       "      <td>287.23167159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012-10-01 16:00:00</td>\n",
       "      <td>282.100480976</td>\n",
       "      <td>289.446243412</td>\n",
       "      <td>281.78244858</td>\n",
       "      <td>291.857503395</td>\n",
       "      <td>291.553209206</td>\n",
       "      <td>293.381212832</td>\n",
       "      <td>296.654466164</td>\n",
       "      <td>285.313345004</td>\n",
       "      <td>284.59253007</td>\n",
       "      <td>...</td>\n",
       "      <td>283.994444444</td>\n",
       "      <td>294.064062959</td>\n",
       "      <td>284.278140131</td>\n",
       "      <td>298.393960613</td>\n",
       "      <td>288.650991196</td>\n",
       "      <td>299.800641223</td>\n",
       "      <td>281.151870096</td>\n",
       "      <td>285.85044048</td>\n",
       "      <td>288.406203155</td>\n",
       "      <td>287.277251086</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              datetime       Portland  San Francisco        Seattle  \\\n",
       "0  2012-10-01 12:00:00           None           None           None   \n",
       "1  2012-10-01 13:00:00         282.08         289.48          281.8   \n",
       "2  2012-10-01 14:00:00  282.083251974  289.474992813  281.797216632   \n",
       "3  2012-10-01 15:00:00  282.091866475  289.460618112  281.789832606   \n",
       "4  2012-10-01 16:00:00  282.100480976  289.446243412   281.78244858   \n",
       "\n",
       "     Los Angeles      San Diego      Las Vegas        Phoenix    Albuquerque  \\\n",
       "0           None           None           None           None           None   \n",
       "1         291.87         291.53         293.41          296.6         285.12   \n",
       "2  291.868185522  291.533500952  293.403141271  296.608508543  285.154558187   \n",
       "3  291.862844459  291.543355079  293.392177052  296.631487354  285.233951595   \n",
       "4  291.857503395  291.553209206  293.381212832  296.654466164  285.313345004   \n",
       "\n",
       "          Denver  ...   Indianapolis        Atlanta        Detroit  \\\n",
       "0           None  ...           None           None           None   \n",
       "1         284.61  ...         283.85         294.03         284.03   \n",
       "2  284.607305531  ...  283.889393939   294.03534141  284.069789234   \n",
       "3    284.5999178  ...  283.941919192  294.049702185  284.173964682   \n",
       "4   284.59253007  ...  283.994444444  294.064062959  284.278140131   \n",
       "\n",
       "    Jacksonville      Charlotte          Miami     Pittsburgh   Philadelphia  \\\n",
       "0           None           None           None           None           None   \n",
       "1         298.17         288.65         299.72          281.0         285.63   \n",
       "2  298.205229759  288.650172214  299.732517698  281.024767377  285.663207797   \n",
       "3  298.299595186  288.650581705   299.76657946  281.088318736  285.756824139   \n",
       "4  298.393960613  288.650991196  299.800641223  281.151870096   285.85044048   \n",
       "\n",
       "        New York         Boston  \n",
       "0           None           None  \n",
       "1         288.22         287.17  \n",
       "2   288.24767617  287.186092094  \n",
       "3  288.326939663   287.23167159  \n",
       "4  288.406203155  287.277251086  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# path dataset\n",
    "path_temperature = os.getcwd() + \"/datasets/historical-hourly-weather-data/temperature.csv\"\n",
    "# dataframe\n",
    "df = spark.read.format(\"csv\").option(\"header\", \"true\").load(path_temperature)\n",
    "df_city = df.select('datetime', *us_cities)\n",
    "df_city.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset provided has a column for each city, that's not the best way to handle this data. That's why we need to unpivot the dataframe and create two new columns called `City` and `Temp`. The `City` column will have every city column in the original dataset and `Temp` will have the temperature for each city every hour.\n",
    "\n",
    "Unpivot Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datetime</th>\n",
       "      <th>City</th>\n",
       "      <th>Temp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012-10-01 13:00:00</td>\n",
       "      <td>Portland</td>\n",
       "      <td>282.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-10-01 13:00:00</td>\n",
       "      <td>SanFrancisco</td>\n",
       "      <td>289.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012-10-01 13:00:00</td>\n",
       "      <td>Seattle</td>\n",
       "      <td>281.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012-10-01 13:00:00</td>\n",
       "      <td>LosAngeles</td>\n",
       "      <td>291.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012-10-01 13:00:00</td>\n",
       "      <td>SanDiego</td>\n",
       "      <td>291.53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Datetime          City    Temp\n",
       "0  2012-10-01 13:00:00      Portland  282.08\n",
       "1  2012-10-01 13:00:00  SanFrancisco  289.48\n",
       "2  2012-10-01 13:00:00       Seattle   281.8\n",
       "3  2012-10-01 13:00:00    LosAngeles  291.87\n",
       "4  2012-10-01 13:00:00      SanDiego  291.53"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# replace spaces in columns\n",
    "df_newcolumn = df_city.toDF(*[column.replace(\" \", \"\") for column in df_city.columns])\n",
    "# unpivot \n",
    "stack_statement = \"stack(27, 'Portland', Portland, 'SanFrancisco', SanFrancisco, 'Seattle', Seattle, 'LosAngeles', LosAngeles, 'SanDiego', SanDiego, 'LasVegas', LasVegas, 'Phoenix', Phoenix, 'Albuquerque', Albuquerque, 'Denver', Denver, 'SanAntonio', SanAntonio, 'Dallas', Dallas, 'Houston', Houston, 'KansasCity', KansasCity, 'Minneapolis', Minneapolis, 'SaintLouis', SaintLouis, 'Chicago', Chicago, 'Nashville', Nashville, 'Indianapolis', Indianapolis, 'Atlanta', Atlanta, 'Detroit', Detroit, 'Jacksonville', Jacksonville, 'Charlotte', Charlotte, 'Miami', Miami, 'Pittsburgh', Pittsburgh, 'Philadelphia', Philadelphia, 'NewYork', NewYork, 'Boston', Boston) as (City, Temp)\"\n",
    "df_weather = df_newcolumn.selectExpr(\"Datetime\", stack_statement).where(\"Temp is not null\")\n",
    "df_weather.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't need the temperature splitted by hour and city, instead, we prefer to group the data by day and city and calculate the average of temperature for every day. Let's do that.\n",
    "\n",
    "Change date format (YYYY-MM-DD) and order by datetime, city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datetime</th>\n",
       "      <th>City</th>\n",
       "      <th>Temp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012-10-01</td>\n",
       "      <td>Albuquerque</td>\n",
       "      <td>285.154558187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-10-01</td>\n",
       "      <td>Albuquerque</td>\n",
       "      <td>285.63091864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012-10-01</td>\n",
       "      <td>Albuquerque</td>\n",
       "      <td>285.392738413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012-10-01</td>\n",
       "      <td>Albuquerque</td>\n",
       "      <td>285.313345004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012-10-01</td>\n",
       "      <td>Albuquerque</td>\n",
       "      <td>285.472131822</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Datetime         City           Temp\n",
       "0  2012-10-01  Albuquerque  285.154558187\n",
       "1  2012-10-01  Albuquerque   285.63091864\n",
       "2  2012-10-01  Albuquerque  285.392738413\n",
       "3  2012-10-01  Albuquerque  285.313345004\n",
       "4  2012-10-01  Albuquerque  285.472131822"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dateutil.parser import parse\n",
    "\n",
    "datetime_udf = F.udf(lambda x: parse(x), T.DateType())\n",
    "\n",
    "df_weatherDate = df_weather.withColumn(\"Datetime\", datetime_udf(df_weather.Datetime))\\\n",
    "                .orderBy(\"Datetime\", \"City\")\n",
    "df_weatherDate.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avg temperature group by day (YYYY-MM-DD) and City"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datetime</th>\n",
       "      <th>City</th>\n",
       "      <th>avg(Temp)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012-10-01</td>\n",
       "      <td>Albuquerque</td>\n",
       "      <td>285.476208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-10-01</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>294.093604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012-10-01</td>\n",
       "      <td>Boston</td>\n",
       "      <td>287.371091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012-10-01</td>\n",
       "      <td>Charlotte</td>\n",
       "      <td>288.651832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012-10-01</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>284.552669</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Datetime         City   avg(Temp)\n",
       "0  2012-10-01  Albuquerque  285.476208\n",
       "1  2012-10-01      Atlanta  294.093604\n",
       "2  2012-10-01       Boston  287.371091\n",
       "3  2012-10-01    Charlotte  288.651832\n",
       "4  2012-10-01      Chicago  284.552669"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_avg_weather =  df_weatherDate.groupBy(\"Datetime\", \"City\").agg({\"Temp\": \"avg\"})\n",
    "df_avg_weather.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Return name of cities to normal (spaces between words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datetime</th>\n",
       "      <th>City</th>\n",
       "      <th>avg(Temp)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012-10-01</td>\n",
       "      <td>Albuquerque</td>\n",
       "      <td>285.476208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-10-01</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>294.093604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012-10-01</td>\n",
       "      <td>Boston</td>\n",
       "      <td>287.371091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012-10-01</td>\n",
       "      <td>Charlotte</td>\n",
       "      <td>288.651832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012-10-01</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>284.552669</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Datetime         City   avg(Temp)\n",
       "0  2012-10-01  Albuquerque  285.476208\n",
       "1  2012-10-01      Atlanta  294.093604\n",
       "2  2012-10-01       Boston  287.371091\n",
       "3  2012-10-01    Charlotte  288.651832\n",
       "4  2012-10-01      Chicago  284.552669"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "\n",
    "replace_cities = {\n",
    "'SanFrancisco': 'San Francisco',\n",
    "'LosAngeles': 'Los Angeles',\n",
    "'SanDiego': 'San Diego',\n",
    "'LasVegas': 'Las Vegas', \n",
    "'SanAntonio': 'San Antonio',\n",
    "'KansasCity': 'Kansas City',\n",
    "'SaintLouis': 'Saint Louis',\n",
    "'NewYork': 'New York',\n",
    "} \n",
    "\n",
    "@udf\n",
    "def replace_city(name):\n",
    "    for key, value in replace_cities.items():\n",
    "        if name == key:\n",
    "            return value\n",
    "    return name\n",
    "\n",
    "\n",
    "df_weatherReplace = df_avg_weather.withColumn('City', replace_city(df_avg_weather.City))\n",
    "df_weatherReplace.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's add the state prefix column into the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datetime</th>\n",
       "      <th>City</th>\n",
       "      <th>avg(Temp)</th>\n",
       "      <th>State</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012-10-01</td>\n",
       "      <td>Albuquerque</td>\n",
       "      <td>285.476208</td>\n",
       "      <td>NM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-10-01</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>294.093604</td>\n",
       "      <td>GA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012-10-01</td>\n",
       "      <td>Boston</td>\n",
       "      <td>287.371091</td>\n",
       "      <td>MA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012-10-01</td>\n",
       "      <td>Charlotte</td>\n",
       "      <td>288.651832</td>\n",
       "      <td>NC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012-10-01</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>284.552669</td>\n",
       "      <td>IL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Datetime         City   avg(Temp) State\n",
       "0  2012-10-01  Albuquerque  285.476208    NM\n",
       "1  2012-10-01      Atlanta  294.093604    GA\n",
       "2  2012-10-01       Boston  287.371091    MA\n",
       "3  2012-10-01    Charlotte  288.651832    NC\n",
       "4  2012-10-01      Chicago  284.552669    IL"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@udf\n",
    "def state(string):\n",
    "    for value in state_city:\n",
    "        if string == value[1]:\n",
    "            return value[0] # value[0] is equal to state prefix\n",
    "    return None # if there's no match return None \n",
    "    \n",
    "df_weatherState = df_weatherReplace.withColumn('State', state(df_weatherReplace.City))\n",
    "df_weatherState.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write Parquet files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weatherState.withColumnRenamed(\"avg(Temp)\", \"Temp\")\\\n",
    "                    .write.partitionBy(\"State\")\\\n",
    "                    .parquet(\"weather.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datetime</th>\n",
       "      <th>City</th>\n",
       "      <th>Temp</th>\n",
       "      <th>State</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-31</td>\n",
       "      <td>San Diego</td>\n",
       "      <td>283.752563</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-31</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>286.552042</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-02-01</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>284.660312</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-02-01</td>\n",
       "      <td>San Diego</td>\n",
       "      <td>284.296771</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-02-01</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>285.360312</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Datetime           City        Temp State\n",
       "0  2015-01-31      San Diego  283.752563    CA\n",
       "1  2015-01-31  San Francisco  286.552042    CA\n",
       "2  2015-02-01    Los Angeles  284.660312    CA\n",
       "3  2015-02-01      San Diego  284.296771    CA\n",
       "4  2015-02-01  San Francisco  285.360312    CA"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_weatherParquet = spark.read.parquet(\"weather.parquet\")\n",
    "df_weatherParquet.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change temperature measurement from Kelvin to Fahrenheit using this metric conversion formula: https://www.metric-conversions.org/temperature/kelvin-to-fahrenheit.htm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datetime</th>\n",
       "      <th>City</th>\n",
       "      <th>Temp</th>\n",
       "      <th>State</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-31</td>\n",
       "      <td>San Diego</td>\n",
       "      <td>51.085</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-31</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>56.124</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-02-01</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>52.719</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-02-01</td>\n",
       "      <td>San Diego</td>\n",
       "      <td>52.064</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-02-01</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>53.979</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Datetime           City    Temp State\n",
       "0  2015-01-31      San Diego  51.085    CA\n",
       "1  2015-01-31  San Francisco  56.124    CA\n",
       "2  2015-02-01    Los Angeles  52.719    CA\n",
       "3  2015-02-01      San Diego  52.064    CA\n",
       "4  2015-02-01  San Francisco  53.979    CA"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fahrenheit_udf = F.udf(lambda x: '%.3f'%((x - 273.15) * 1.8000 + 32.00)) # return a three decimal float number\n",
    "\n",
    "df_weatherFahrenheit = df_weatherParquet.withColumn(\"Temp\", fahrenheit_udf(df_weatherParquet.Temp))\n",
    "df_weatherFahrenheit.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our Dataframe is almost ready, all we have to do now is change the name of every column to lower for a better practice.\n",
    "\n",
    "Rename and lower columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>city</th>\n",
       "      <th>temp</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-31</td>\n",
       "      <td>San Diego</td>\n",
       "      <td>51.085</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-31</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>56.124</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-02-01</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>52.719</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-02-01</td>\n",
       "      <td>San Diego</td>\n",
       "      <td>52.064</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-02-01</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>53.979</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     datetime           city    temp state\n",
       "0  2015-01-31      San Diego  51.085    CA\n",
       "1  2015-01-31  San Francisco  56.124    CA\n",
       "2  2015-02-01    Los Angeles  52.719    CA\n",
       "3  2015-02-01      San Diego  52.064    CA\n",
       "4  2015-02-01  San Francisco  53.979    CA"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = [column.lower() for column in df_weatherFahrenheit.columns]\n",
    "df_weatherLower = df_weatherFahrenheit.toDF(*columns)\n",
    "df_weatherLower.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Dataframe looks really good. Now we can write the data into Postgres.\n",
    "\n",
    "Write into Postgres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unncomment to execute\n",
    "# df_weatherFahrenheit.write.mode(\"append\").jdbc(url=url_db, table=\"dim_us_weather\", properties=properties)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Dimension Table: `dim_airport` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset has all airport codes, types, and location for all cities of the US. \n",
    "For the purpose of this project, we only need a few columns like type, country, region, and municipality\n",
    "\n",
    "Columns for `dim_airport`: \n",
    "- __id_airport__: ID code for each airport of US\n",
    "- __type__: Type of airport, like small airport, large, heliport, etc.\n",
    "- __name__: Name of the airport\n",
    "- __country__: Country were the airport is located\n",
    "- __state__: State were the airport is located\n",
    "- __city__: City were the airport is located\n",
    "\n",
    "First, read the dataset and analyze which columns we have. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ident</th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>elevation_ft</th>\n",
       "      <th>continent</th>\n",
       "      <th>iso_country</th>\n",
       "      <th>iso_region</th>\n",
       "      <th>municipality</th>\n",
       "      <th>gps_code</th>\n",
       "      <th>iata_code</th>\n",
       "      <th>local_code</th>\n",
       "      <th>coordinates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00A</td>\n",
       "      <td>heliport</td>\n",
       "      <td>Total Rf Heliport</td>\n",
       "      <td>11</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>US-PA</td>\n",
       "      <td>Bensalem</td>\n",
       "      <td>00A</td>\n",
       "      <td>None</td>\n",
       "      <td>00A</td>\n",
       "      <td>-74.93360137939453, 40.07080078125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00AA</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Aero B Ranch Airport</td>\n",
       "      <td>3435</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>US-KS</td>\n",
       "      <td>Leoti</td>\n",
       "      <td>00AA</td>\n",
       "      <td>None</td>\n",
       "      <td>00AA</td>\n",
       "      <td>-101.473911, 38.704022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00AK</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Lowell Field</td>\n",
       "      <td>450</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AK</td>\n",
       "      <td>Anchor Point</td>\n",
       "      <td>00AK</td>\n",
       "      <td>None</td>\n",
       "      <td>00AK</td>\n",
       "      <td>-151.695999146, 59.94919968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00AL</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Epps Airpark</td>\n",
       "      <td>820</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AL</td>\n",
       "      <td>Harvest</td>\n",
       "      <td>00AL</td>\n",
       "      <td>None</td>\n",
       "      <td>00AL</td>\n",
       "      <td>-86.77030181884766, 34.86479949951172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00AR</td>\n",
       "      <td>closed</td>\n",
       "      <td>Newport Hospital &amp; Clinic Heliport</td>\n",
       "      <td>237</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AR</td>\n",
       "      <td>Newport</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>-91.254898, 35.6087</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ident           type                                name elevation_ft  \\\n",
       "0   00A       heliport                   Total Rf Heliport           11   \n",
       "1  00AA  small_airport                Aero B Ranch Airport         3435   \n",
       "2  00AK  small_airport                        Lowell Field          450   \n",
       "3  00AL  small_airport                        Epps Airpark          820   \n",
       "4  00AR         closed  Newport Hospital & Clinic Heliport          237   \n",
       "\n",
       "  continent iso_country iso_region  municipality gps_code iata_code  \\\n",
       "0        NA          US      US-PA      Bensalem      00A      None   \n",
       "1        NA          US      US-KS         Leoti     00AA      None   \n",
       "2        NA          US      US-AK  Anchor Point     00AK      None   \n",
       "3        NA          US      US-AL       Harvest     00AL      None   \n",
       "4        NA          US      US-AR       Newport     None      None   \n",
       "\n",
       "  local_code                            coordinates  \n",
       "0        00A     -74.93360137939453, 40.07080078125  \n",
       "1       00AA                 -101.473911, 38.704022  \n",
       "2       00AK            -151.695999146, 59.94919968  \n",
       "3       00AL  -86.77030181884766, 34.86479949951172  \n",
       "4       None                    -91.254898, 35.6087  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = spark.read.format(\"csv\").option(\"header\", \"true\").load(os.getcwd() + \"/datasets/airport-codes_csv.csv\")\n",
    "df.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As our main dataset is related to US immigration. The table `dim_airport` will only have US airports. \n",
    "This dataframe will be filtered by country = 'US'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ident</th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>iso_country</th>\n",
       "      <th>iso_region</th>\n",
       "      <th>municipality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00A</td>\n",
       "      <td>heliport</td>\n",
       "      <td>Total Rf Heliport</td>\n",
       "      <td>US</td>\n",
       "      <td>US-PA</td>\n",
       "      <td>Bensalem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00AA</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Aero B Ranch Airport</td>\n",
       "      <td>US</td>\n",
       "      <td>US-KS</td>\n",
       "      <td>Leoti</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00AK</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Lowell Field</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AK</td>\n",
       "      <td>Anchor Point</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00AL</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Epps Airpark</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AL</td>\n",
       "      <td>Harvest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00AR</td>\n",
       "      <td>closed</td>\n",
       "      <td>Newport Hospital &amp; Clinic Heliport</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AR</td>\n",
       "      <td>Newport</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ident           type                                name iso_country  \\\n",
       "0   00A       heliport                   Total Rf Heliport          US   \n",
       "1  00AA  small_airport                Aero B Ranch Airport          US   \n",
       "2  00AK  small_airport                        Lowell Field          US   \n",
       "3  00AL  small_airport                        Epps Airpark          US   \n",
       "4  00AR         closed  Newport Hospital & Clinic Heliport          US   \n",
       "\n",
       "  iso_region  municipality  \n",
       "0      US-PA      Bensalem  \n",
       "1      US-KS         Leoti  \n",
       "2      US-AK  Anchor Point  \n",
       "3      US-AL       Harvest  \n",
       "4      US-AR       Newport  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_airport = df.filter('iso_country = \"US\" and municipality is not null').select('ident', 'type', 'name', 'iso_country', 'iso_region', 'municipality')\n",
    "df_airport.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a new column for state using iso_region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ident</th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>iso_country</th>\n",
       "      <th>state</th>\n",
       "      <th>municipality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00A</td>\n",
       "      <td>heliport</td>\n",
       "      <td>Total Rf Heliport</td>\n",
       "      <td>US</td>\n",
       "      <td>PA</td>\n",
       "      <td>Bensalem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00AA</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Aero B Ranch Airport</td>\n",
       "      <td>US</td>\n",
       "      <td>KS</td>\n",
       "      <td>Leoti</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00AK</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Lowell Field</td>\n",
       "      <td>US</td>\n",
       "      <td>AK</td>\n",
       "      <td>Anchor Point</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00AL</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Epps Airpark</td>\n",
       "      <td>US</td>\n",
       "      <td>AL</td>\n",
       "      <td>Harvest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00AR</td>\n",
       "      <td>closed</td>\n",
       "      <td>Newport Hospital &amp; Clinic Heliport</td>\n",
       "      <td>US</td>\n",
       "      <td>AR</td>\n",
       "      <td>Newport</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ident           type                                name iso_country state  \\\n",
       "0   00A       heliport                   Total Rf Heliport          US    PA   \n",
       "1  00AA  small_airport                Aero B Ranch Airport          US    KS   \n",
       "2  00AK  small_airport                        Lowell Field          US    AK   \n",
       "3  00AL  small_airport                        Epps Airpark          US    AL   \n",
       "4  00AR         closed  Newport Hospital & Clinic Heliport          US    AR   \n",
       "\n",
       "   municipality  \n",
       "0      Bensalem  \n",
       "1         Leoti  \n",
       "2  Anchor Point  \n",
       "3       Harvest  \n",
       "4       Newport  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "udf_state = F.udf(lambda x: x[3::])\n",
    "df_airport_state = df_airport.withColumn('iso_region', udf_state(df_airport.iso_region))\n",
    "df_airport_state = df_airport_state.withColumnRenamed('iso_region', 'state')\n",
    "df_airport_state.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change name of columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_airport</th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>country</th>\n",
       "      <th>state</th>\n",
       "      <th>city</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00A</td>\n",
       "      <td>heliport</td>\n",
       "      <td>Total Rf Heliport</td>\n",
       "      <td>US</td>\n",
       "      <td>PA</td>\n",
       "      <td>Bensalem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00AA</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Aero B Ranch Airport</td>\n",
       "      <td>US</td>\n",
       "      <td>KS</td>\n",
       "      <td>Leoti</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00AK</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Lowell Field</td>\n",
       "      <td>US</td>\n",
       "      <td>AK</td>\n",
       "      <td>Anchor Point</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00AL</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Epps Airpark</td>\n",
       "      <td>US</td>\n",
       "      <td>AL</td>\n",
       "      <td>Harvest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00AR</td>\n",
       "      <td>closed</td>\n",
       "      <td>Newport Hospital &amp; Clinic Heliport</td>\n",
       "      <td>US</td>\n",
       "      <td>AR</td>\n",
       "      <td>Newport</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id_airport           type                                name country state  \\\n",
       "0        00A       heliport                   Total Rf Heliport      US    PA   \n",
       "1       00AA  small_airport                Aero B Ranch Airport      US    KS   \n",
       "2       00AK  small_airport                        Lowell Field      US    AK   \n",
       "3       00AL  small_airport                        Epps Airpark      US    AL   \n",
       "4       00AR         closed  Newport Hospital & Clinic Heliport      US    AR   \n",
       "\n",
       "           city  \n",
       "0      Bensalem  \n",
       "1         Leoti  \n",
       "2  Anchor Point  \n",
       "3       Harvest  \n",
       "4       Newport  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = ['id_airport', 'type', 'name', 'country', 'state', 'city']\n",
    "df_airportNew = df_airport_state.toDF(*columns)\n",
    "df_airportNew.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write into Postgres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment to execute\n",
    "# df_airportNew.write.mode(\"overwrite\").jdbc(url=url_db, table=\"dim_airport\", properties=properties)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 4. Dimension Table: `dim_country` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This table will be the relationship for `Citizen` and `Resident` columns in the fact table immigration.\n",
    "\n",
    "All data came from `I94_SAS_Labels_Descriptions.SAS` file and is used as a Data Dictionary for the main dataset.\n",
    "\n",
    "We created a `.py` file with all key, values for this columns, this file can be found in `datasets/data.py`\n",
    "\n",
    "Columns for `dim_country`: \n",
    "- __id_country__: ID country, related to us immigration dictionary. This code is related to the column `citizen` and `resident` for every immigrant in the main dataset.\n",
    "- __country__: Name of the country were the immigrant is a citizen and resident. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_country</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>582</td>\n",
       "      <td>MEXICO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>236</td>\n",
       "      <td>AFGHANISTAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>101</td>\n",
       "      <td>ALBANIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>316</td>\n",
       "      <td>ALGERIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>102</td>\n",
       "      <td>ANDORRA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id_country      country\n",
       "0        582       MEXICO\n",
       "1        236  AFGHANISTAN\n",
       "2        101      ALBANIA\n",
       "3        316      ALGERIA\n",
       "4        102      ANDORRA"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets.data import Data\n",
    "\n",
    "columns = ['id_country', 'country']\n",
    "\n",
    "df_country = spark.createDataFrame([(key,value) for key, value in Data.countries.items()], schema=columns)\n",
    "df_country.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write into Postgres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment to execute\n",
    "# df_country.write.mode(\"overwrite\").jdbc(url=url_db, table=\"dim_country\", properties=properties)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. US Immigration Fact Table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is our main table to be created, as we said before, all other tables (dim tables) can be matched by state prefix with our fact table `(immigration_us)`\n",
    "\n",
    "\n",
    "This data came from US National Tourism and Trade Office: https://travel.trade.gov/research/reports/i94/historical/2016.html \n",
    "\n",
    "\n",
    "Columns for `immigration_us`:\n",
    "\n",
    "* __id__: Unique ID for every row in the dataset.\n",
    "* __year__: Year of entry into US.\n",
    "* __month__: Month of entry into US.\n",
    "* __citizen__: Country code where the immigrant is an official citizen.\n",
    "* __resident__: Country code where the immigrant is an official resident.\n",
    "* __port_entry__: Port of entry into US.\n",
    "* __mode_entry__: Mode of entry, like air, sea, land, etc. \n",
    "* __arrival_date__: Date of arrival.\n",
    "* __dep_date__: Departure date.\n",
    "* __dateadd_to__: Date to which admitted to U.S. (allowed to stay until).\n",
    "* __state_addr__: State address where the immigrant will stay. \n",
    "* __birth_year__: Year of birth.\n",
    "* __age__: Age of immigrant in years.\n",
    "* __gender__: Immigrant sex.\n",
    "* __visa_code__: Visa category code: 1- Business, 2- Pleasure, 3- Student.\n",
    "* __visa_type__: Class of admission legally admitting the non-immigrant to temporarily stay in U.S \n",
    "* __airline__: Airline used to arrive in the U.S. If correspond. \n",
    "\n",
    "This dataset needs to be read in SAS format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "ss = SparkSession\\\n",
    "        .builder\\\n",
    "        .config(\"spark.jars.packages\",\"saurfang:spark-sas7bdat:2.1.0-s_2.11\")\\\n",
    "        .enableHiveSupport()\\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../../data/18-83510-I94-Data-2016/*.sas7bdat'\n",
    "df = ss.read.format(\"com.github.saurfang.sas.spark\").load(path)\n",
    "# write parquet\n",
    "df.write.parquet(\"datasets/sas_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cicid</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94res</th>\n",
       "      <th>i94port</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>i94addr</th>\n",
       "      <th>depdate</th>\n",
       "      <th>...</th>\n",
       "      <th>entdepu</th>\n",
       "      <th>matflag</th>\n",
       "      <th>biryear</th>\n",
       "      <th>dtaddto</th>\n",
       "      <th>gender</th>\n",
       "      <th>insnum</th>\n",
       "      <th>airline</th>\n",
       "      <th>admnum</th>\n",
       "      <th>fltno</th>\n",
       "      <th>visatype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5748517.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>438.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>20574.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CA</td>\n",
       "      <td>20582.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1976.0</td>\n",
       "      <td>10292016</td>\n",
       "      <td>F</td>\n",
       "      <td>None</td>\n",
       "      <td>QF</td>\n",
       "      <td>9.495387e+10</td>\n",
       "      <td>00011</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5748518.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>438.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>20574.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NV</td>\n",
       "      <td>20591.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1984.0</td>\n",
       "      <td>10292016</td>\n",
       "      <td>F</td>\n",
       "      <td>None</td>\n",
       "      <td>VA</td>\n",
       "      <td>9.495562e+10</td>\n",
       "      <td>00007</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5748519.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>438.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>20574.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>WA</td>\n",
       "      <td>20582.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1987.0</td>\n",
       "      <td>10292016</td>\n",
       "      <td>M</td>\n",
       "      <td>None</td>\n",
       "      <td>DL</td>\n",
       "      <td>9.495641e+10</td>\n",
       "      <td>00040</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5748520.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>438.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>20574.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>WA</td>\n",
       "      <td>20588.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1987.0</td>\n",
       "      <td>10292016</td>\n",
       "      <td>F</td>\n",
       "      <td>None</td>\n",
       "      <td>DL</td>\n",
       "      <td>9.495645e+10</td>\n",
       "      <td>00040</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5748521.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>438.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>20574.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>WA</td>\n",
       "      <td>20588.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1988.0</td>\n",
       "      <td>10292016</td>\n",
       "      <td>M</td>\n",
       "      <td>None</td>\n",
       "      <td>DL</td>\n",
       "      <td>9.495639e+10</td>\n",
       "      <td>00040</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       cicid   i94yr  i94mon  i94cit  i94res i94port  arrdate  i94mode  \\\n",
       "0  5748517.0  2016.0     4.0   245.0   438.0     LOS  20574.0      1.0   \n",
       "1  5748518.0  2016.0     4.0   245.0   438.0     LOS  20574.0      1.0   \n",
       "2  5748519.0  2016.0     4.0   245.0   438.0     LOS  20574.0      1.0   \n",
       "3  5748520.0  2016.0     4.0   245.0   438.0     LOS  20574.0      1.0   \n",
       "4  5748521.0  2016.0     4.0   245.0   438.0     LOS  20574.0      1.0   \n",
       "\n",
       "  i94addr  depdate  ...  entdepu  matflag  biryear   dtaddto gender insnum  \\\n",
       "0      CA  20582.0  ...     None        M   1976.0  10292016      F   None   \n",
       "1      NV  20591.0  ...     None        M   1984.0  10292016      F   None   \n",
       "2      WA  20582.0  ...     None        M   1987.0  10292016      M   None   \n",
       "3      WA  20588.0  ...     None        M   1987.0  10292016      F   None   \n",
       "4      WA  20588.0  ...     None        M   1988.0  10292016      M   None   \n",
       "\n",
       "  airline        admnum  fltno visatype  \n",
       "0      QF  9.495387e+10  00011       B1  \n",
       "1      VA  9.495562e+10  00007       B1  \n",
       "2      DL  9.495641e+10  00040       B1  \n",
       "3      DL  9.495645e+10  00040       B1  \n",
       "4      DL  9.495639e+10  00040       B1  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read parquet file\n",
    "df = ss.read.parquet(\"datasets/sas_data\")\n",
    "df.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we need to change the columns `arrdate` and `depdate`. This columns are in SAS numeric date format. \n",
    "\n",
    "We need to create a udf function to apply a conversion for these columns. Due to `depdate` has some null values, we need to apply an if/else statement into our udf function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "142457"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.filter(\"depdate is null\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cicid</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94res</th>\n",
       "      <th>i94port</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>i94addr</th>\n",
       "      <th>depdate</th>\n",
       "      <th>...</th>\n",
       "      <th>entdepu</th>\n",
       "      <th>matflag</th>\n",
       "      <th>biryear</th>\n",
       "      <th>dtaddto</th>\n",
       "      <th>gender</th>\n",
       "      <th>insnum</th>\n",
       "      <th>airline</th>\n",
       "      <th>admnum</th>\n",
       "      <th>fltno</th>\n",
       "      <th>visatype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5748517.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>438.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>2016-04-30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CA</td>\n",
       "      <td>2016-05-08</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1976.0</td>\n",
       "      <td>10292016</td>\n",
       "      <td>F</td>\n",
       "      <td>None</td>\n",
       "      <td>QF</td>\n",
       "      <td>9.495387e+10</td>\n",
       "      <td>00011</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5748518.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>438.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>2016-04-30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NV</td>\n",
       "      <td>2016-05-17</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1984.0</td>\n",
       "      <td>10292016</td>\n",
       "      <td>F</td>\n",
       "      <td>None</td>\n",
       "      <td>VA</td>\n",
       "      <td>9.495562e+10</td>\n",
       "      <td>00007</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5748519.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>438.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>2016-04-30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>WA</td>\n",
       "      <td>2016-05-08</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1987.0</td>\n",
       "      <td>10292016</td>\n",
       "      <td>M</td>\n",
       "      <td>None</td>\n",
       "      <td>DL</td>\n",
       "      <td>9.495641e+10</td>\n",
       "      <td>00040</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5748520.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>438.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>2016-04-30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>WA</td>\n",
       "      <td>2016-05-14</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1987.0</td>\n",
       "      <td>10292016</td>\n",
       "      <td>F</td>\n",
       "      <td>None</td>\n",
       "      <td>DL</td>\n",
       "      <td>9.495645e+10</td>\n",
       "      <td>00040</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5748521.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>438.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>2016-04-30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>WA</td>\n",
       "      <td>2016-05-14</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1988.0</td>\n",
       "      <td>10292016</td>\n",
       "      <td>M</td>\n",
       "      <td>None</td>\n",
       "      <td>DL</td>\n",
       "      <td>9.495639e+10</td>\n",
       "      <td>00040</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       cicid   i94yr  i94mon  i94cit  i94res i94port     arrdate  i94mode  \\\n",
       "0  5748517.0  2016.0     4.0   245.0   438.0     LOS  2016-04-30      1.0   \n",
       "1  5748518.0  2016.0     4.0   245.0   438.0     LOS  2016-04-30      1.0   \n",
       "2  5748519.0  2016.0     4.0   245.0   438.0     LOS  2016-04-30      1.0   \n",
       "3  5748520.0  2016.0     4.0   245.0   438.0     LOS  2016-04-30      1.0   \n",
       "4  5748521.0  2016.0     4.0   245.0   438.0     LOS  2016-04-30      1.0   \n",
       "\n",
       "  i94addr     depdate  ...  entdepu  matflag  biryear   dtaddto gender insnum  \\\n",
       "0      CA  2016-05-08  ...     None        M   1976.0  10292016      F   None   \n",
       "1      NV  2016-05-17  ...     None        M   1984.0  10292016      F   None   \n",
       "2      WA  2016-05-08  ...     None        M   1987.0  10292016      M   None   \n",
       "3      WA  2016-05-14  ...     None        M   1987.0  10292016      F   None   \n",
       "4      WA  2016-05-14  ...     None        M   1988.0  10292016      M   None   \n",
       "\n",
       "  airline        admnum  fltno visatype  \n",
       "0      QF  9.495387e+10  00011       B1  \n",
       "1      VA  9.495562e+10  00007       B1  \n",
       "2      DL  9.495641e+10  00040       B1  \n",
       "3      DL  9.495645e+10  00040       B1  \n",
       "4      DL  9.495639e+10  00040       B1  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "from dateutil.parser import parse\n",
    "\n",
    "epoch = datetime(1960,1,1)\n",
    "\n",
    "sas_days = F.udf(lambda x: (timedelta(days=int(x)) + epoch) if x else None, T.DateType())\n",
    "\n",
    "df_dateParse = df.withColumn(\"arrdate\", sas_days(df.arrdate))\n",
    "df_dateParse2 = df_dateParse.withColumn(\"depdate\", sas_days(df_dateParse.depdate))\n",
    "df_dateParse2.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's another date column that we need to change called `depdate` which refers to date allowed to stay in U.S \n",
    "\n",
    "This is a date character field but some rows have a weird format, so we may not be able to transform every row. That's why the function created needs to handle this problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(dtaddto='183'),\n",
       " Row(dtaddto=None),\n",
       " Row(dtaddto='10 02003'),\n",
       " Row(dtaddto='D/S'),\n",
       " Row(dtaddto='06 02002'),\n",
       " Row(dtaddto='/   183D')]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dateParse2.select('dtaddto').where('(length(dtaddto) < 8) or (dtaddto is null) or dtaddto rlike \"[a-zA-Z]|[ ]\"').distinct().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45824"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dateParse2.filter('(length(dtaddto) < 8) or (dtaddto is null) or dtaddto rlike \"[a-zA-Z]|[ ]\"').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a function that change the format of dtatto to date and return null if row format is not correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cicid</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94res</th>\n",
       "      <th>i94port</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>i94addr</th>\n",
       "      <th>depdate</th>\n",
       "      <th>...</th>\n",
       "      <th>entdepu</th>\n",
       "      <th>matflag</th>\n",
       "      <th>biryear</th>\n",
       "      <th>dtaddto</th>\n",
       "      <th>gender</th>\n",
       "      <th>insnum</th>\n",
       "      <th>airline</th>\n",
       "      <th>admnum</th>\n",
       "      <th>fltno</th>\n",
       "      <th>visatype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5748517.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>438.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>2016-04-30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CA</td>\n",
       "      <td>2016-05-08</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1976.0</td>\n",
       "      <td>2016-10-29</td>\n",
       "      <td>F</td>\n",
       "      <td>None</td>\n",
       "      <td>QF</td>\n",
       "      <td>9.495387e+10</td>\n",
       "      <td>00011</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5748518.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>438.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>2016-04-30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NV</td>\n",
       "      <td>2016-05-17</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1984.0</td>\n",
       "      <td>2016-10-29</td>\n",
       "      <td>F</td>\n",
       "      <td>None</td>\n",
       "      <td>VA</td>\n",
       "      <td>9.495562e+10</td>\n",
       "      <td>00007</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5748519.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>438.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>2016-04-30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>WA</td>\n",
       "      <td>2016-05-08</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1987.0</td>\n",
       "      <td>2016-10-29</td>\n",
       "      <td>M</td>\n",
       "      <td>None</td>\n",
       "      <td>DL</td>\n",
       "      <td>9.495641e+10</td>\n",
       "      <td>00040</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5748520.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>438.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>2016-04-30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>WA</td>\n",
       "      <td>2016-05-14</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1987.0</td>\n",
       "      <td>2016-10-29</td>\n",
       "      <td>F</td>\n",
       "      <td>None</td>\n",
       "      <td>DL</td>\n",
       "      <td>9.495645e+10</td>\n",
       "      <td>00040</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5748521.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>438.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>2016-04-30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>WA</td>\n",
       "      <td>2016-05-14</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1988.0</td>\n",
       "      <td>2016-10-29</td>\n",
       "      <td>M</td>\n",
       "      <td>None</td>\n",
       "      <td>DL</td>\n",
       "      <td>9.495639e+10</td>\n",
       "      <td>00040</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       cicid   i94yr  i94mon  i94cit  i94res i94port     arrdate  i94mode  \\\n",
       "0  5748517.0  2016.0     4.0   245.0   438.0     LOS  2016-04-30      1.0   \n",
       "1  5748518.0  2016.0     4.0   245.0   438.0     LOS  2016-04-30      1.0   \n",
       "2  5748519.0  2016.0     4.0   245.0   438.0     LOS  2016-04-30      1.0   \n",
       "3  5748520.0  2016.0     4.0   245.0   438.0     LOS  2016-04-30      1.0   \n",
       "4  5748521.0  2016.0     4.0   245.0   438.0     LOS  2016-04-30      1.0   \n",
       "\n",
       "  i94addr     depdate  ...  entdepu  matflag  biryear     dtaddto gender  \\\n",
       "0      CA  2016-05-08  ...     None        M   1976.0  2016-10-29      F   \n",
       "1      NV  2016-05-17  ...     None        M   1984.0  2016-10-29      F   \n",
       "2      WA  2016-05-08  ...     None        M   1987.0  2016-10-29      M   \n",
       "3      WA  2016-05-14  ...     None        M   1987.0  2016-10-29      F   \n",
       "4      WA  2016-05-14  ...     None        M   1988.0  2016-10-29      M   \n",
       "\n",
       "  insnum airline        admnum  fltno visatype  \n",
       "0   None      QF  9.495387e+10  00011       B1  \n",
       "1   None      VA  9.495562e+10  00007       B1  \n",
       "2   None      DL  9.495641e+10  00040       B1  \n",
       "3   None      DL  9.495645e+10  00040       B1  \n",
       "4   None      DL  9.495639e+10  00040       B1  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "\n",
    "def char_date(string):\n",
    "    try:\n",
    "        return datetime.strptime(str(string), '%m%d%Y')\n",
    "    except:\n",
    "        return None\n",
    "    \n",
    "udf_charDate = udf(char_date, T.DateType())\n",
    "\n",
    "df_charDate =  df_dateParse2.withColumn(\"dtaddto\", udf_charDate(df_dateParse2.dtaddto))\n",
    "df_charDate.limit(5).toPandas()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- cicid: double (nullable = true)\n",
      " |-- i94yr: double (nullable = true)\n",
      " |-- i94mon: double (nullable = true)\n",
      " |-- i94cit: double (nullable = true)\n",
      " |-- i94res: double (nullable = true)\n",
      " |-- i94port: string (nullable = true)\n",
      " |-- arrdate: date (nullable = true)\n",
      " |-- i94mode: double (nullable = true)\n",
      " |-- i94addr: string (nullable = true)\n",
      " |-- depdate: date (nullable = true)\n",
      " |-- i94bir: double (nullable = true)\n",
      " |-- i94visa: double (nullable = true)\n",
      " |-- count: double (nullable = true)\n",
      " |-- dtadfile: string (nullable = true)\n",
      " |-- visapost: string (nullable = true)\n",
      " |-- occup: string (nullable = true)\n",
      " |-- entdepa: string (nullable = true)\n",
      " |-- entdepd: string (nullable = true)\n",
      " |-- entdepu: string (nullable = true)\n",
      " |-- matflag: string (nullable = true)\n",
      " |-- biryear: double (nullable = true)\n",
      " |-- dtaddto: date (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- insnum: string (nullable = true)\n",
      " |-- airline: string (nullable = true)\n",
      " |-- admnum: double (nullable = true)\n",
      " |-- fltno: string (nullable = true)\n",
      " |-- visatype: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_charDate.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change Double columns to Int. and build our final table based on this columns \n",
    "\n",
    "'cicid', \n",
    "'i94yr', \n",
    "'i94mon', \n",
    "'i94cit', \n",
    "'i94res', \n",
    "'i94port', 'i94mode', 'arrdate', 'depdate', 'dtaddto', 'i94addr', 'biryear', 'i94bir', 'gender', 'i94visa', 'visatype', 'airline'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- cicid: integer (nullable = true)\n",
      " |-- i94yr: integer (nullable = true)\n",
      " |-- i94mon: integer (nullable = true)\n",
      " |-- i94cit: integer (nullable = true)\n",
      " |-- i94res: integer (nullable = true)\n",
      " |-- i94port: string (nullable = true)\n",
      " |-- i94mode: integer (nullable = true)\n",
      " |-- arrdate: date (nullable = true)\n",
      " |-- depdate: date (nullable = true)\n",
      " |-- dtaddto: date (nullable = true)\n",
      " |-- i94addr: string (nullable = true)\n",
      " |-- biryear: integer (nullable = true)\n",
      " |-- i94bir: integer (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- i94visa: integer (nullable = true)\n",
      " |-- visatype: string (nullable = true)\n",
      " |-- airline: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "to_int = F.udf(lambda x: int(x) if x else None, T.IntegerType())\n",
    "\n",
    "columns = ['cicid', 'i94yr', 'i94mon', 'i94cit', 'i94res', 'i94port', 'i94mode', 'arrdate', 'depdate', 'dtaddto', 'i94addr', 'biryear', 'i94bir', 'gender', 'i94visa', 'visatype', 'airline']\n",
    "\n",
    "df_immigration = df_charDate.withColumn(\"cicid\", to_int(df_charDate.cicid))\\\n",
    "                .withColumn(\"i94yr\", to_int(df_charDate.i94yr))\\\n",
    "                .withColumn(\"i94mon\", to_int(df_charDate.i94mon))\\\n",
    "                .withColumn(\"i94cit\", to_int(df_charDate.i94cit))\\\n",
    "                .withColumn(\"i94res\", to_int(df_charDate.i94res))\\\n",
    "                .withColumn(\"i94mode\", to_int(df_charDate.i94mode))\\\n",
    "                .withColumn(\"biryear\", to_int(df_charDate.biryear))\\\n",
    "                .withColumn(\"i94bir\", to_int(df_charDate.i94bir))\\\n",
    "                .withColumn(\"i94visa\", to_int(df_charDate.i94visa))\\\n",
    "                .select(*columns)\n",
    "\n",
    "df_immigration.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cicid</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94res</th>\n",
       "      <th>i94port</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>depdate</th>\n",
       "      <th>dtaddto</th>\n",
       "      <th>i94addr</th>\n",
       "      <th>biryear</th>\n",
       "      <th>i94bir</th>\n",
       "      <th>gender</th>\n",
       "      <th>i94visa</th>\n",
       "      <th>visatype</th>\n",
       "      <th>airline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5748517</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>245</td>\n",
       "      <td>438</td>\n",
       "      <td>LOS</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-04-30</td>\n",
       "      <td>2016-05-08</td>\n",
       "      <td>2016-10-29</td>\n",
       "      <td>CA</td>\n",
       "      <td>1976</td>\n",
       "      <td>40</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>B1</td>\n",
       "      <td>QF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5748518</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>245</td>\n",
       "      <td>438</td>\n",
       "      <td>LOS</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-04-30</td>\n",
       "      <td>2016-05-17</td>\n",
       "      <td>2016-10-29</td>\n",
       "      <td>NV</td>\n",
       "      <td>1984</td>\n",
       "      <td>32</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>B1</td>\n",
       "      <td>VA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5748519</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>245</td>\n",
       "      <td>438</td>\n",
       "      <td>LOS</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-04-30</td>\n",
       "      <td>2016-05-08</td>\n",
       "      <td>2016-10-29</td>\n",
       "      <td>WA</td>\n",
       "      <td>1987</td>\n",
       "      <td>29</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>B1</td>\n",
       "      <td>DL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5748520</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>245</td>\n",
       "      <td>438</td>\n",
       "      <td>LOS</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-04-30</td>\n",
       "      <td>2016-05-14</td>\n",
       "      <td>2016-10-29</td>\n",
       "      <td>WA</td>\n",
       "      <td>1987</td>\n",
       "      <td>29</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>B1</td>\n",
       "      <td>DL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5748521</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>245</td>\n",
       "      <td>438</td>\n",
       "      <td>LOS</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-04-30</td>\n",
       "      <td>2016-05-14</td>\n",
       "      <td>2016-10-29</td>\n",
       "      <td>WA</td>\n",
       "      <td>1988</td>\n",
       "      <td>28</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>B1</td>\n",
       "      <td>DL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     cicid  i94yr  i94mon  i94cit  i94res i94port  i94mode     arrdate  \\\n",
       "0  5748517   2016       4     245     438     LOS        1  2016-04-30   \n",
       "1  5748518   2016       4     245     438     LOS        1  2016-04-30   \n",
       "2  5748519   2016       4     245     438     LOS        1  2016-04-30   \n",
       "3  5748520   2016       4     245     438     LOS        1  2016-04-30   \n",
       "4  5748521   2016       4     245     438     LOS        1  2016-04-30   \n",
       "\n",
       "      depdate     dtaddto i94addr  biryear  i94bir gender  i94visa visatype  \\\n",
       "0  2016-05-08  2016-10-29      CA     1976      40      F        1       B1   \n",
       "1  2016-05-17  2016-10-29      NV     1984      32      F        1       B1   \n",
       "2  2016-05-08  2016-10-29      WA     1987      29      M        1       B1   \n",
       "3  2016-05-14  2016-10-29      WA     1987      29      F        1       B1   \n",
       "4  2016-05-14  2016-10-29      WA     1988      28      M        1       B1   \n",
       "\n",
       "  airline  \n",
       "0      QF  \n",
       "1      VA  \n",
       "2      DL  \n",
       "3      DL  \n",
       "4      DL  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_immigration.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change name of columns for immigration dataframe/table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>citizen</th>\n",
       "      <th>resident</th>\n",
       "      <th>port_entry</th>\n",
       "      <th>mode_entry</th>\n",
       "      <th>arrival_date</th>\n",
       "      <th>dep_date</th>\n",
       "      <th>dateadd_to</th>\n",
       "      <th>state_addr</th>\n",
       "      <th>birth_year</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>visa_code</th>\n",
       "      <th>visa_type</th>\n",
       "      <th>airline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5748517</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>245</td>\n",
       "      <td>438</td>\n",
       "      <td>LOS</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-04-30</td>\n",
       "      <td>2016-05-08</td>\n",
       "      <td>2016-10-29</td>\n",
       "      <td>CA</td>\n",
       "      <td>1976</td>\n",
       "      <td>40</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>B1</td>\n",
       "      <td>QF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5748518</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>245</td>\n",
       "      <td>438</td>\n",
       "      <td>LOS</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-04-30</td>\n",
       "      <td>2016-05-17</td>\n",
       "      <td>2016-10-29</td>\n",
       "      <td>NV</td>\n",
       "      <td>1984</td>\n",
       "      <td>32</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>B1</td>\n",
       "      <td>VA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5748519</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>245</td>\n",
       "      <td>438</td>\n",
       "      <td>LOS</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-04-30</td>\n",
       "      <td>2016-05-08</td>\n",
       "      <td>2016-10-29</td>\n",
       "      <td>WA</td>\n",
       "      <td>1987</td>\n",
       "      <td>29</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>B1</td>\n",
       "      <td>DL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5748520</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>245</td>\n",
       "      <td>438</td>\n",
       "      <td>LOS</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-04-30</td>\n",
       "      <td>2016-05-14</td>\n",
       "      <td>2016-10-29</td>\n",
       "      <td>WA</td>\n",
       "      <td>1987</td>\n",
       "      <td>29</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>B1</td>\n",
       "      <td>DL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5748521</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>245</td>\n",
       "      <td>438</td>\n",
       "      <td>LOS</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-04-30</td>\n",
       "      <td>2016-05-14</td>\n",
       "      <td>2016-10-29</td>\n",
       "      <td>WA</td>\n",
       "      <td>1988</td>\n",
       "      <td>28</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>B1</td>\n",
       "      <td>DL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  year  month  citizen  resident port_entry  mode_entry  \\\n",
       "0  5748517  2016      4      245       438        LOS           1   \n",
       "1  5748518  2016      4      245       438        LOS           1   \n",
       "2  5748519  2016      4      245       438        LOS           1   \n",
       "3  5748520  2016      4      245       438        LOS           1   \n",
       "4  5748521  2016      4      245       438        LOS           1   \n",
       "\n",
       "  arrival_date    dep_date  dateadd_to state_addr  birth_year  age gender  \\\n",
       "0   2016-04-30  2016-05-08  2016-10-29         CA        1976   40      F   \n",
       "1   2016-04-30  2016-05-17  2016-10-29         NV        1984   32      F   \n",
       "2   2016-04-30  2016-05-08  2016-10-29         WA        1987   29      M   \n",
       "3   2016-04-30  2016-05-14  2016-10-29         WA        1987   29      F   \n",
       "4   2016-04-30  2016-05-14  2016-10-29         WA        1988   28      M   \n",
       "\n",
       "   visa_code visa_type airline  \n",
       "0          1        B1      QF  \n",
       "1          1        B1      VA  \n",
       "2          1        B1      DL  \n",
       "3          1        B1      DL  \n",
       "4          1        B1      DL  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_columns = ['id', 'year', 'month', 'citizen', 'resident', 'port_entry', 'mode_entry', 'arrival_date', 'dep_date', 'dateadd_to', 'state_addr', 'birth_year', 'age', 'gender', 'visa_code', 'visa_type', 'airline']\n",
    "\n",
    "df_imm = df_immigration.toDF(*new_columns)\n",
    "df_imm.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a variable which contains the total rows for the Dataframe, this variable will be useful for a Data Quality process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3096313"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_dataframe = df_imm.count()\n",
    "total_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write into Postgres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment to execute\n",
    "# df_imm.write.mode(\"append\").jdbc(url=url_db, table=\"immigration_us\", properties=properties)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Quality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the purpose of this project, we are going to check two main tables and apply a data quality process to make sure that the data was written without problems.\n",
    "\n",
    "1. The first data quality process will be a count between the data in the Spark Dataframe and immigration_us table after the writing process. For this we're going to make a count method using Spark and then make a select into immigration_us table. This check will be valid if the count for the Spark Dataframe and the select count(1) for the table are equals.\n",
    "\n",
    "2. The second data quality process will be a check if there's a problem with the arrival date value. This is a very import column because every immigrant needs to have an arrival date, so if for some reason this column is entire null, our Datawarehouse is not useful for Analytics and Machine Learning.\n",
    "\n",
    "3. The third data quality process will be a count into our dim_us_temp table. The idea is always to have a temperature available is we want to make a join between immigration_us and dim_us_temp tables. That's why we're going to select all years of our main dataset and validate if we have a temperature available for these years.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a connection for PostgresSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(\"host=127.0.0.1 dbname=imm_dwh user=student password=student\")\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SQL queries for Data Quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_imm_count = \"\"\"\n",
    "    SELECT COUNT(1) FROM IMMIGRATION_US;\n",
    "\"\"\"\n",
    "\n",
    "select_arrival_date = \"\"\"\n",
    "    SELECT \n",
    "    SUM(CASE WHEN ARRIVAL_DATE IS NULL THEN 1 ELSE 0 END) NULL_VALUES,\n",
    "    SUM(CASE WHEN ARRIVAL_DATE IS NOT NULL THEN 1 ELSE 0 END) NOT_NULL_VALUES  \n",
    "    FROM IMMIGRATION_US;\n",
    "\"\"\"\n",
    "\n",
    "select_year_imm = \"\"\"\n",
    "    SELECT DISTINCT YEAR\n",
    "    FROM IMMIGRATION_US\n",
    "    ORDER BY YEAR;\n",
    "\"\"\"\n",
    "\n",
    "select_year_weather = \"\"\"\n",
    "    SELECT DISTINCT CAST(EXTRACT(YEAR FROM datetime) AS INTEGER) AS YEAR \n",
    "    FROM DIM_US_WEATHER \n",
    "    ORDER BY YEAR;\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. First Data Quality check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Quality check passed Successfully!\n",
      "\n",
      "Total values in dataframe: 3096313\n",
      "Total values in table: 3096313\n"
     ]
    }
   ],
   "source": [
    "cur.execute(select_imm_count)\n",
    "count = cur.fetchall()\n",
    "\n",
    "if total_dataframe == count[0][0]:\n",
    "    print(f\"Data Quality check passed Successfully!\\n\\nTotal values in dataframe: {total_dataframe}\\nTotal values in table: {count[0][0]}\")\n",
    "else:\n",
    "    print(f\"Data Quality check failed! \\nTotal values in dataframe: {total_dataframe}\\n Total values in table: {count[0][0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Second Data Quality check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Quality check passed Successfully!\n",
      "\n",
      "Total null values: 0\n",
      "Total not null values: 3096313\n"
     ]
    }
   ],
   "source": [
    "cur.execute(select_arrival_date)\n",
    "result = cur.fetchall()\n",
    "\n",
    "if result[0][1] > 0 and result[0][1] > result[0][0]:\n",
    "    print(f\"Data Quality check passed Successfully!\\n\\nTotal null values: {result[0][0]}\\nTotal not null values: {result[0][1]}\")\n",
    "else: \n",
    "    print(f\"Data Quality check failed!\\n\\nTotal null values: {result[0][0]}\\n Total not null values: {result[0][1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Third Data Quality check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Quality check passed Successfully!\n"
     ]
    }
   ],
   "source": [
    "from itertools import chain\n",
    "\n",
    "# check for distinct years in immigration_us table\n",
    "cur.execute(select_year_imm)\n",
    "result_1 = cur.fetchall()\n",
    "\n",
    "# check for distint years in dim_us_temp table\n",
    "cur.execute(select_year_weather)\n",
    "result_2 = cur.fetchall()\n",
    "\n",
    "\n",
    "if result_1[0][0] in chain.from_iterable(result_2):\n",
    "    print(f\"Data Quality check passed Successfully!\")\n",
    "else:\n",
    "    print(f\"Data Quality check failed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Close connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FAQs about the project\n",
    "\n",
    "* __What is the rationale for the choice of tools and technologies for the project?__\n",
    "\n",
    "__Apache Spark__\n",
    "\n",
    "We choose to work with Spark having in mind the scalability that may upcoming from our dataset and have the ability to transform data quickly at scale. For example, Pandas in an amazing library and you can accomplish pretty much all of this code using it but is most suitable for working with data that fits into one single machine. So what can happen if we want to process data for 2016, 2017, 2018, 2019? That's not a good approach for Pandas library. This is when Spark shine. Spark will help us to distribute over the cluster doing all tasks faster and without bottleneck. At the moment we're just running a spark job on-premises but we can deploy this on EC2 and take all advantages of AWS. \n",
    "\n",
    "Another reason of why we choose Spark is his impressive Machine Learning library MLib. This project was created having in mind to build a structured Datawarehouse suitable for Analysis and Machine Learning. So if the company wants to make use of all this data and apply Machine Learning models, Spark is the best choice. \n",
    "\n",
    "Cleaning the data for Data Analysis is a crucial process, Spark helps us with this too with the capacity to deploy Dataframes and analyze the data before inserting into the database. This provides data integration in the Datawarehouse. \n",
    "\n",
    "__PostgreSQL__\n",
    "\n",
    "Postgres provide an excellent synergy with Spark. You can write a Spark Dataframe into a Postgres database without the necessity to create a table. \n",
    "\n",
    "Postgres is a relational database, this fits perfectly with the scope of the project and if in the future we want to migrate the entire database into AWS, Amazon Redshift was built based on Postgres 8.0.2, so this provides less work and problems if we have to implement constraints, triggers, stored procedures, etc. It's relevant to say that the syntax of queries is the same too.\n",
    "\n",
    "\n",
    "* __How often the data should be updated and why?__\n",
    "\n",
    "Our main dataset immigration has information every day. But it's not crucial to update the data for every new row. We need to have in mind that this dataset can be joined with weather information, city population, airport, and states. \n",
    "\n",
    "Immigration and weather tables can be updated one time a day, why? because the weather table provides temperature information grouped by day and city. In this way, when we run the ETL, the data from the day before will be processed and calculate the average temperature for every city. At the same time, we can load the data for immigrants.\n",
    "\n",
    "The other datasets like city population, airport and states can be updated one or two times a year. We need to have in mind that this dataset doesn't change in a long time. The next Census is scheduled to 2020, so the period of an update is relatively long compared to the other datasets.\n",
    "\n",
    "\n",
    "* __How to approach the problem differently under the following scenarios:__\n",
    " * __The data was increased by 100x.__\n",
    " \n",
    "This project is actually running on a single machine. If the data increase by 100x, first of all, we need to migrate the data to the cloud. A good approach is to use EMR on AWS, the idea is to execute this notebook, save the data in parquet files into an S3 bucket and provide information for BI tools and machine learning models.\n",
    "\n",
    "One of the benefits of implementing EMR is the pricing, we pay per-instant rate for every second used. This means that we don't have to be running EC2 machines 24hours daily to execute a job 1 hour a day. We just pay for the hour of service used.\n",
    "\n",
    "Another benefit is his auto-scaling. We can provide one or thousands of compute instances to process the data. We can increase or decrease the number of nodes manually or with auto-scaling. This is a good deal is we are not totally sure about how many nodes we need to process the data. This also means that we spend less time tuning and monitoring the clusters.\n",
    "\n",
    "\n",
    "![img](datasets/cycle_2.png)\n",
    "\n",
    " \n",
    " * __The data populates a dashboard that must be updated on a daily basis by 7am every day.__\n",
    " \n",
    "To schedule a job, a good approach is to make use of Apache Airflow. We can accomplish pretty much the same using CRON scheduler but Apache Airflow provides a more robust system. With Apache Airflow we have the ability to monitor, schedule and re-run failed events. \n",
    "\n",
    "To run a Spark Job using Apache Airflow we can make use of our `etl.py` file. This file is the same process than this notebook but instead, it doesn't made use of the analysis process, the file just read, clean and write data into Postgres. \n",
    "\n",
    "Using a BashOperator we can create a task and indicate in the bash_command variable the .py file we want to submit. \n",
    "\n",
    "A good tutorial to accomplish this task can be found here: [link](https://blog.insightdatascience.com/scheduling-spark-jobs-with-airflow-4c66f3144660)\n",
    "\n",
    " * __The database needed to be accessed by 100+ people.__\n",
    "\n",
    "For this purpose, the database needs to migrate to the cloud. A good approach will be make use of Amazon Redshift. \n",
    "\n",
    "We can create groups for security and control access for the entire organization, e.g design a group for every department of the company. In this way, we don't compromise the information.\n",
    "\n",
    "Amazon Redshift is based on Postgres 8.0.2. If we want to migrate the data into Redshift, first we may need to make some adjustments like constraints, and SQL syntax. For example, if we have a table that makes use of ON CONFLICT constraint. We have to implement this task using other methods, like select distinct, or filter the data before insert. This is because Postgres 8.0.2 doesn't provide this kind of constraints like Postgres 11."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
